---
title: "Introduction to Linear Models -- Simple Linear Regression"
author: "Stat 331"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["xaringan-themer.css", "slide-style.css"]
    nature:
      highlightStyle: solarized-light
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      slideNumberFormat: |
        <div class="progress-bar-container">
          <div class="progress-bar" style="width: calc(%current% / %total% * 100%);">
          </div>
        </div>
---


```{r, echo = FALSE, message = FALSE, warning = FALSE, fig.width = 8, fig.height = 6}
knitr::opts_chunk$set(fig.align = "center", 
                      message = FALSE, 
                      warning = FALSE)

options(htmltools.dir.version = FALSE)
options(show.signif.stars = FALSE)

library(openintro)
library(broom)
library(gridExtra)
library(kableExtra)
library(png)
library(xaringanthemer)
library(xaringan)
library(tidyverse)
library(flair)


style_duo_accent(
  primary_color      = "#0F4C81", # pantone classic blue
  secondary_color    = "#B6CADA", # pantone baby blue
  header_font_google = google_font("Raleway"),
  text_font_google   = google_font("Raleway", "300", "300i"),
  code_font_google   = google_font("Source Code Pro"),
  text_font_size     = "30px"
)
```

class: inverse

.larger[The Data]

The `ncbirths` dataset is a random sample of 1,000 cases taken from a larger 
dataset collected in North Carolina in 2004. 

Each case describes the birth of a single child born in North Carolina, along
with various characteristics of the child (e.g. birth weight, length of
gestation, etc.), the child’s mother (e.g. age, weight gained during pregnancy,
smoking habits, etc.) and the child’s father (e.g. age). 

---

.larger[Relationships Between Variables]

**In a statistical model, we generally have one variable that is the output and
one or more variables that are the inputs.**  

.pull-left[
- Response variable
  * a.k.a. $y$, dependent
  * The quantity you want to understand
]

.pull-right[
- Explanatory variable
  * a.k.a. $x$, independent, explanatory, predictor
  * Something you think might be related to the response
]


---

.larger[Visualizing Linear Regression]

.pull-left[
**The scatterplot has been called the most "generally useful invention in the
history of statistical graphics."** 
]

.pull-right[
```{r 2, echo = FALSE, fig.width = 5, fig.height = 4, fig.align = 'center'}
ggplot(data = bdims, aes(y = wgt, x = hgt)) + 
  geom_point() +
  scale_x_continuous("Explanatory Variable", labels = NULL) + 
  scale_y_continuous("Response Variable", labels = NULL)
```
]


---

class: middle

.larger[Characterizing Relationships]

- Form -- linear, quadratic, non-linear?

- Direction -- positive, negative?

- Strength -- how much scatter/noise?

- Unusual observations -- do points not fit the overall pattern?


---

.larger[Your Turn]

.pull-left[
How would your characterize this relationship? 

- shape
- direction
- strength 
- outliers
]

.pull-right[

```{r, echo = FALSE, fig.height = 6}
ncbirths %>% 
ggplot(aes(x = weeks, y = weight)) +
  geom_jitter() + 
  labs(x = "Length of pregnancy (in weeks)",
       y = "Birth weight of baby (in lbs)")
```
]

<!-- As we work through these, please keep in mind that much of what we are doing at -->
<!-- this stage involves making judgment calls. This is part of the nature of -->
<!-- statistics, and while it can be frustrating - especially as a beginner - it is -->
<!-- inescapable. For better or for worse, statistics is not a field where there is -->
<!-- one right answer. There are of course an infinite number of indefensible claims, -->
<!-- but many judgments are open to interpretation. -->



<!-- <!-- There isn’t a universal, hard-and-fast definition of what constitutes -->
<!-- <!-- an outlier, but they are often easy to spot in a scatterplot. -->

<!-- - What observations would you consider to be outliers?  -->

<!-- - How would you go about removing these outliers from the data?  -->

---

class: inverse 

.larger[Linear Regression]

<!-- Models are ubiquitous in statistics. In many cases, we assume that the value of -->
<!-- our response variable is some function of our explanatory variable, plus some -->
<!-- random noise.  -->

<!-- What we are saying here is that there is some mathematical function $f$, which can translate values of one variable into values of another, except that there is some randomness in the process. What often distinguishes statisticians from other quantitative researchers is the way that we try to model that random noise.  -->

Assume the relationship between $x$ and $y$ takes the form of a linear function.

$$
  response = intercept + slope \cdot explanatory + noise
$$
</br> 

--

.pull-left[
Population Regression Model

$Y = \beta_0 + \beta_1 \cdot X + \epsilon_i$  

$\epsilon \sim N(0, \sigma)$
]

--

.pull-right[Fitted Regression Model  

$\hat{y} = \hat{\beta}_0 + \hat{\beta}_1 \cdot x$
]

---

class: center, middle

.bitlarger[**Fitting a Linear Model**]

</br>

```{r smooth, echo = FALSE, eval = FALSE}
ncbirths %>% 
ggplot(aes(x = gained, y = weight)) +
  geom_jitter() + 
  geom_smooth(method = "lm") 

m1 <- ncbirths %>% 
  lm(weight ~ gained, data = .)
```

```{r, echo = FALSE}
decorate_chunk("smooth", eval = FALSE) %>%
  flair('method = "lm"') %>% 
  flair("lm")
```

---

.larger[Interpretting a Linear Regression]

.pull-left[
```{r}
m1 <- ncbirths %>% 
  lm(weight ~ weeks, data = .)

coef(m1)
```
]

.pull-right[
- Intercept: Expected __mean__ value for $y$, when $x$ is 0  

- Slope: Expected change in the __mean__ of $y$, when $x$ is increased by 1 unit
]


---

class: inverse

.larger[Assessing Model Fit]

.pull-left[
- **Sum of Square Errors (SSE)**
  * sum of squared residuals 

- **Root Mean Square Error (RMSE)**
  * standard deviation of residuals 
]

--

.pull-right[
- **$R^2$** 
  * proportion of variability in response accounted for by the linear model
]


---

.larger[Model Comparison]

.pull-left[
```{r, echo = TRUE}
weight_weeks <- ncbirths %>% 
  lm(weight ~ weeks, data = .)
```

- SSE = 1246.55 
- RMSE = 1.119
- $R^2$ = 0.449
]

.pull-right[
```{r, echo = TRUE}
weight_visits <- ncbirths %>% 
  lm(weight ~ visits, data = .)
```

- SSE = 2152.74
- RMSE = 1.475
- $R^2$ = 0.01819
]
