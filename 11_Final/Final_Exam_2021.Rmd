---
title: "Final Exam - First Half"
author: 'Stat 331: Spring 2021'
output: rmdformats::readthedown
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      eval = FALSE, 
                      message = FALSE, 
                      warning = FALSE)
```

```{r, eval = TRUE, include = FALSE}
library(tidyverse)
library(infer)
library(palmerpenguins)
```

```{r, eval = TRUE}
np_trails <- read_csv(here::here("11_Final", 
                                 "national_park_trails.csv"))
```

## Introduction

This exam is due by **8:00am** on **Wednesday, June 9th**.
Late exams will be docked by a penalty of at least 50%, possibly more.
**Please do not turn your exam in late!!!**

Please create a new R Markdown file for parts two and three of this exam.
Make sure your files are set up to display **all** your source code when knitted.

Clearly mark the questions, so that I can easily find your answers to grade them.
Please **DO NOT** use nonstandard R Markdown templates for this exam.

Although you are not directly graded on data exploration, cleaning, and
adjusting, you will certainly need to do this to properly address the questions.

### Policies
  * You may use: any online resources, including anything posted on Canvas. 
  * You may NOT contact anyone, inside or outside this class, during the course
  of the exam.  This includes email, chat/messenger services, and posting on
  online forums and message boards.
  * You may NOT use exam materials from previous years.
  * Violations of academic honesty include accessing and using any illegal
  materials, and giving or receiving help on this exam including looking at
  other student's exams, allowing other students to look at your own exam, 
  and/or revealing any information about this exam or future exams to someone
  who has not yet taken it.
  * Students who exhibit academic misconduct will be reported to the Office of
  Student Rights and Responsibilities; academic dishonesty may be punishable by
  a grade of F in this course.
  * You may **not** discuss the exam with any other students until after the
  exams have been returned to all students.
  * If you witness others exhibiting academic misconduct, you have a duty to
  report them to your professor.

### Instructions
  * Please note that you will need to use the data documentation in order to
  successfully complete this exam.
  * The problems on this exam do not necessarily need to be completed
  sequentially, e.g., if you cannot accomplish problem 1, you may still be able
  to accomplish problem 2.
  * Some parts to problems may need to be completed sequentially. If you cannot
  complete part (a), please outline code or your thought process for completing
  part (b).
  * All questions should be answered **using R code**.  Make sure your code
  prints out only the information that directly answers the question.  
  **Penalties will be given if your `.html` file has extra output beyond that which answers the question.**
  * If your code has errors that you cannot fix in time, you may also include in
  the comments explanations of your thought process, to potentially receive
  partial credit.
  * Submit both your `.Rmd` and `.html` files on Canvas by the end of the
  allotted time. However, only your `.html` file will be graded - make sure the
  knitted output contains all your answers.
  
</br>

---

</br>

## Part One: Functions & Iteration  [50 points]

<center>
### This portion of the exam should take you approximately 30-45 minutes.
</center>


__1.__ Emma is interested in writing a function that handles the various ways 
missing values are coded by different researchers. Emma has also found three 
ways `NA` values are coded for character vectors: `"."`, `""`, and `"NaN"`. Emma
would like to write a function that handles all of these cases. 

Consider the following function skeleton: 

```{r, echo = TRUE}
na_function <- function(x){
  case_when(x == "." ~ ____, 
            x == "" ~ ____, 
            x == "NaN" ~ ____)
}
```

```{r, eval = TRUE}
na_function <- function(x){
  case_when(x == "." ~ NA_character_, 
            x == "" ~ NA_character_, 
            x == "NaN" ~ NA_character_, 
            TRUE ~ x)
}
```


__(a)__ What should Emma insert as the values after each `~` 
(in place of the `____`)?

- `NA`
- `NA_real_`
- `NA_character_`  
- `"NA"`

__(b)__ Currently, this function converts every value of the character vector
into an `NA`. What is missing from the function that will return the value of
`x`, if `x` is not equal to `"."`, `""`, or `"NaN"`? 

**Your response should be _one_ line of code!**

</br> 

__2.__ Emma would like to write a new function `df_na()` that takes a dataframe
and a variable as inputs, and uses the `na_function()` to replace the values
for the variable input. Additionally, Emma envisions using either 
`df_na(dataset, "variable")` or `df_na(dataset, vars(variable))` as the input 
to the function. 

Which of the following functions will correctly carry out this process? The
function can either return the dataframe with the variable adjusted *or* a 
vector with the adjusted variable.

**Select all that apply**

__(a)__
```{r, echo = TRUE}
df_na <- function(df, var){
  df %>% 
    mutate(var = na_function(var))
}
```

__(b)__
```{r, echo = TRUE}
df_na <- function(df, var){
  na_function(df[var])
}
```

__(c)__
```{r, echo = TRUE}
df_na <- function(df, var){
  df %>% 
    mutate_at(var, na_function)
}
```

__(d)__
```{r, echo = TRUE}
df_na <- function(df, var){
  na_function(df[[var]])
}
```

</br>

__3.__ Now, with the `na_function()` and `df_na()` functions in hand, Emma wants 
to clean up an example dataset. Emma decides to use the `penguins` dataset to 
test out these functions. Emma knows that it is better to use `map()` functions 
to do repeated operations, but isn't sure why her code isn't working. 

```{r, echo = TRUE, eval = TRUE, error = TRUE}
penguins %>% 
  map_dfc(vars(species, island, sex), df_na)
```

Which of the following are reasons for the above code returning an error?

**Select all that apply**

__(a)__ `map_chr()` should be used instead of `map_dfc()`

__(b)__ `df_na()` takes two arguments and it is only being supplied one input

__(c)__ `vars()` is not correctly selecting the variables

__(d)__ `map()` functions work with vectors, not dataframes

</br>

__4.__ Which of the following methods could Emma use to replace the missing 
values of the character variables in the `penguins` dataset? 

**Select all that apply**

__(a)__ 

```{r, echo = TRUE}
penguins %>% 
  mutate_if(is.character, df_na)
```

__(b)__

```{r, echo = TRUE}
penguins %>% 
  df_na(var = vars(species, island, sex))
```

__(c)__

```{r, echo = TRUE}
penguins %>% 
  mutate_at(vars(species, island, sex), na_function)
```


__(d)__

```{r, echo = TRUE}
penguins %>% 
  mutate_all(~df_na(df = .))
```

</br>

---

</br>

## Part Two: Short answer questions [100 points]

<center>
### This portion of the exam should take you approximately 60-90 minutes.
</center>

### The Data

National parks were a big part of my childhood, with lots of family trips around 
the US. National parks offer a great respite from the busyness of life, but are 
often overwhelming in the number and variety of trails you can hike on! For this
portion of the exam you will summarize some characteristics of the trails at a 
variety of national parks, using data contributed from users of AllTrails. 

The dataset was taken from the *AllTrails* app, which allows users to input
new trails and rate existing ones.
You can find documentation on the dataset from its creator 
[here](https://www.kaggle.com/planejane/national-park-trails).

Variables in the data are:

* `trail_id`: An ID number for the trail
* `name`: Name of the trail
* `area_name`: National Park where the trial is located
* `city_name`: City where the trail is located
* `state_name`: State where the trail is located
* `country_name`: Country where the trail is located
* `_geoloc`: Latitude and longitude of trail
* `popularity`: A score from 0 to 100 of how often the trail is used.
* `length`: Distance covered by trail (in meters).
* `elevation_gain`: How much uphill is on the trail (in meters).
* `difficulty_rating`: Average user rating of trail difficulty
* `route_type`: Type of trail (loop, out and back, or point to point)
* `visitor_usage`: (Honestly, I'm not sure what this one is.)
* `avg_rating`: The average visitor rating of the trail (1 to 5 stars)
* `num_reviews`: The total number of reviews on the app for that trail
* `features`: Notable elements about the trail
* `activities`: Common uses for the trail
* `units`: **This variable is a lie!** All the lengths are in meters.


Answer each of the following using code. The output of the code should clearly 
and directly answer the question.  You do not need to provide any text answers;
only code and output.  For example, if the question is, "What is the longest
bill length of any penguin in the dataset?", you might provide:

```{r, echo = TRUE, eval = TRUE}
library(palmerpenguins)

penguins %>% 
  slice_max(n = 1, bill_length_mm) %>%
  select(bill_length_mm)
```

#### Question 1.1  [10 points]

Which National Park contains the most trails with a 5-star average rating?

```{r}
np_trails %>%
  filter(avg_rating == 5) %>%
  count(area_name) %>%
  slice_max(n = 1, n)
```


#### Question 1.2 [10 points]

What are the three longest trails in this dataset, in miles?

```{r}
np_trails %>%
  mutate(
    length_miles = length*3.28/5280
  ) %>%
  slice_max(n = 3, length_miles) %>%
  select(name, area_name, length_miles)
```

#### Question 1.3 [10 points]

What is the most popular trail in each National Park?

```{r}
np_trails %>%
  group_by(area_name) %>%
  slice_max(popularity) %>% 
  select(name, area_name)
```



#### Question 1.4 [10 points]

How many National Parks contain the word "Canyon" somewhere in their name?

```{r}
np_trails %>%
  distinct(area_name) %>%
  pull(area_name) %>%
  str_detect("[Cc]anyon") %>%
  sum()
```

#### Question 1.5 [20 points]

What are the five common words used in trail names?

Do not include besides words that mean "trail", like "trail", "route", "path",
"loop".

Do not include connector words like "to", "and", "with", "via", etc.

```{r}
trail_words <- np_trails %>%
  pull(name) %>%
  str_extract_all("\\w+") %>%
  unlist() 

word_counts <- tibble(
  word = trail_words) %>%
  count(word, sort = TRUE)

# Lake
# Creek
# Mountain
# Falls
# Canyon
```

#### Question 1.6 [20 points]

Write a function that takes as input the dataset and the name of a National
Park, and the following optional arguments:

* A minimum trail length (in miles)
* A maximum trail length (in miles)
* A minimum trail rating
* The type of trail

The function should return all the trails that fit the supplied criteria. You
**may** assume that the variable names of the inputted dataset match the
`np_trails` dataset.

Include the following code in your response to verify that your function works:

```{r}
recommend_trails <- function(data, park_name, min_len = 0, 
                             max_len = Inf, min_rating = 0, type = NULL) {
  
  if (!is.null(type)) {
    data <- data %>%
      filter(route_type == type)
  }
  
  trails <- data %>%
    mutate(
      length = length*3.3/5280
    ) %>%
    filter(
      area_name == park_name,
      length > min_len,
      length < max_len,
      avg_rating > min_rating
    )
  
  return(trails)
  
}
```


```{r, echo = TRUE}
np_trails %>%
  recommend_trails("Yellowstone National Park", 
                   min_len = 10, 
                   min_rating = 4, 
                   type = "loop")
```


#### Question 1.7 [20 points]

Use your function from Question 1.6, along with a `map()` or `apply()` function,
to recommend to me all the trails that are:

- 20-40  miles long  (good for a two day backpacking trip!)

- Rated at least a 4.5

- Loop trails (I don't like to retrace my steps)

- In one of the parks I can drive to from San Luis Obispo:
    * Sequoia National Park
    * Joshua Tree National Park
    * Lassen Volcanic National Park
    * Kings Canyon National Park
    * Pinnacles National Park
    * Death Valley National Park
    * Redwood National Park 

```{r}
parks <- c("Sequoia National Park",
           "Joshua Tree National Park",
           "Lassen Volcanic National Park",
           "Kings Canyon National Park",
           "Death Valley National Park",
           "Redwood National Park")

map_dfr(parks, ~recommend_trails(np_trails, .x, 
                                 min_len = 20, 
                                 max_len = 40, 
                                 min_rating = 4.5,
                                 type = "loop"))
```

<!-- --- -->


<!-- ## Part Three: Compare the Parks [150 points] -->

<!-- <center> -->
<!-- ### This portion of the exam should take you approximately 75-90 minutes. -->
<!-- </center> -->

<!-- The two National Parks closest to San Luis Obispo are **Kings Canyon** and -->
<!-- **Sequoia**. These two parks border each other, and are managed under a single -->
<!-- forest service; sometimes, they are simply referred to together as "SeKi". -->

<!-- But are they actually meaningfully different parks?  Let's find out! -->

<!-- In this section, please show your code and output, but also include appropriate -->
<!-- text discussion to interpret the output and answer the question. -->

<!-- ```{r, echo = FALSE, eval = FALSE} -->
<!-- seki <- np_trails %>%  -->
<!--   filter(str_detect(area_name, "Kings|Sequoia") == TRUE) -->
<!-- ``` -->


<!-- ### Trail Steepness [50 points] -->

<!-- Do these parks have different steepness of trails? -->

<!-- Create a visualization that explores the elevation gain of trails in SeKi as a -->
<!-- function of the trail length, for trails in Sequoia and Kings Canyon. You should -->
<!-- also include the type of trail in your visualization.  -->

<!-- Describe the relationships that you see in the visualization. At a minimum, you  -->
<!-- should address the following questions:   -->

<!-- - Does it appear that the relationship between a trail's steepness and its  -->
<!-- length is linear? -->

<!-- - Does it appear that the relationship between steepness and length is different -->
<!-- for the two national parks? -->

<!-- - How does the relationship between steepness and length differ by the type of -->
<!-- trail? -->

<!-- Your visualization should be something you would include in a written report. -->
<!-- At a bare minimum you must have:   -->

<!-- - clear axis labels -->
<!-- - clear legend labels -->
<!-- - meaningful plot title -->

<!-- ```{r, echo = FALSE, eval = FALSE} -->
<!-- seki %>% -->
<!--   mutate(length_miles = length * 3.28/ 5280) %>%  -->
<!--   ggplot(aes(x = length_miles, y = elevation_gain, color = area_name)) +  -->
<!--   geom_point() + -->
<!--   stat_smooth(method = "lm") +  -->
<!--   facet_wrap(~route_type) -->
<!-- ``` -->

<!-- ### Multiple Linear Regression [50 points] -->

<!-- We are interested in building a model for predicting the steepness of a  -->
<!-- trail at SeKi. We would like for the model to explain as much variability in  -->
<!-- steepness as possible, but as be as simple as possible. Thus, we will use AIC  -->
<!-- as our model selection criteria. You can extract the AIC of a model using the  -->
<!-- built-in `AIC()` function, like so:  -->

<!-- ```{r, echo = TRUE, eval = TRUE} -->
<!-- m1 <- np_trails %>%  -->
<!--   lm(elevation_gain ~ length, data = .) -->

<!-- AIC(m1) -->
<!-- ``` -->

<!-- AIC has a slightly different selection procedure to adjusted $R^2$. First, -->
<!-- smaller values of AIC are better. Second, if two models have AIC values within  -->
<!-- 2 units of each other (e.g. 12 and 11.3), then you cannot say that one model is  -->
<!-- "better" than the other model. Instead, you can say they have "essentially the  -->
<!-- same fit."  -->

<!-- Using AIC as the model selection criteria, find the "best" model that predicts -->
<!-- a trails steepness based on the variables included in this dataset. Your model  -->
<!-- should only consider variables independently (i.e. no interactions).  -->

<!-- Report your top two models and their associated AIC values.  -->

<!-- ```{r, eval = FALSE, echo = FALSE} -->
<!-- large_model <- lm(elevation_gain ~ length + difficulty_rating + popularity +  -->
<!--                     avg_rating + route_type, data = np_trails) -->
<!-- stepAIC(large_model,  -->
<!--         direction = "both",  -->
<!--         scope = list(lower = ~1), -->
<!--         trace = TRUE) -->

<!-- # Final model chosen: -->
<!-- final_lm <- lm(elevation_gain ~ length + difficulty_rating +  -->
<!--                  avg_rating + route_type, data = np_trails) -->

<!-- ``` -->

<!-- </br>  -->

<!-- ### Predictions for Other Parks [50 points] -->

<!-- Now, we're going to see how your model does for predicting the steepness of  -->
<!-- trails at other national parks! We've use the `predict()` function to get the  -->
<!-- predicted values for the dataset used when fitting the regression model (in  -->
<!-- `lm()`), but we haven't used `predict()` to get predictions for a new dataset.  -->

<!-- To make predictions for a new dataset, you need to (1) assemble the new dataset  -->
<!-- to use, and (2) pass the new dataset into the `newdata` argument of `predict()`. -->

<!-- Use the model you chose in the last part to make predictions for the steepness  -->
<!-- of the trail for **all** of the other national parks (every park except  -->
<!-- Sequoia & Kings Canyon).  -->

<!-- With the predicted elevation gains, create a scatterplot of the -->
<!-- residuals versus predicted values. Describe the relationship you see in the -->
<!-- plot.  -->

<!-- ```{r, eval = FALSE, echo = FALSE} -->

<!-- other_parks <- np_trails %>%  -->
<!--   filter(!str_detect(area_name, "Sequoia|Kings")) -->

<!-- other_parks <- other_parks %>%  -->
<!--   mutate(residuals = elevation_gain - predict(final_lm, newdata = other_parks),  -->
<!--          predict_elevation = predict(final_lm, newdata = other_parks)) -->

<!-- other_parks %>%  -->
<!--   ggplot(aes(x = elevation_gain, y = residuals)) +  -->
<!--   geom_point() -->

<!-- ``` -->


<!-- </br> -->

<!-- --- -->

<!-- </br> -->

<!-- ## Part Four: Description of Code [50 points] -->

<!-- <center> -->
<!-- ### This portion of the exam will be take 10 minutes over Zoom. -->
<!-- </center> -->

<!-- **Question 1** -->

<!-- Describe how you chose your "best" model from Part Three. If you used a  -->
<!-- function to iterate through a set of possible models, walk me through what the  -->
<!-- function does. If you did not use iteration, describe to me how you would  -->
<!-- transform your method to use iteration instead.  -->

<!-- **Question 2** -->

<!-- Suppose you are helping another student with their R code for a research project  -->
<!-- they are working on. Going through their code, you notice they seem to copy and -->
<!-- paste the same process multiple times in lots of different locations. What -->
<!-- changes would you suggest they make? Why do you think these changes are -->
<!-- important? -->
