---
title: "Practice Activity 3: Data Wrangling with dplyr üè´"
format: 
  html: 
    theme: minty
    fontsize: 1em
    mainfont: sans-serif
    number-sections: true
    number-depth: 2
    code-block-bg: "#76b5c5"
    highlight-style: monochrome
editor: visual
execute: 
  eval: false
---

Today you will be using the dplyr package to clean a dataset and then using that cleaned dataset to figure out what college Ephelia has been accepted to.

## Dealing with errors

As you work through this PA, you will encounter some code that does not work as you want it to. Don't despair! Errors (when R is unable to run your code) and bugs (when the code doesn't do what you hoped) are a natural part of coding. Even the best of the best deal with these problems regularly - learning to track down the issue is a skill that you can learn and practice.

## Advice for dealing with errors

**Errors can be sneaky - check results *often***

If a chunk of code runs smoothly without giving you any error or warnings this **does not** necessarily mean it accomplished the desired task.

It is a good habit to check the results of your code **every time** you finish a task. In general, I would recommend completing the following tasks **every time** you write a code chunk.

-   Include a comment at the beginning of the code chunk that briefly states what the purpose of the chunk is. Comments in the code chunks come after `#` signs. These comments will remind later readers---which might be your future self!---what the desired output of the code chunk is.

-   If you created a new object, take a look at it! You can inspect the object by either clicking its name in your *Environment* tab or by typing its name into the console. Make sure it looks about how you expect. **Do not** type code to inspect the object in your Quarto file, as that **is not** code that needs to be saved!

-   If you created or updated a data frame, make sure your edits did what you hoped. Use the *Environment* or the `head()` and `glimpse()` functions to investigate your changes.

**Two heads are better than one**

It can be hard to spot bugs in code that you wrote.

Work with those around you - if something goes wrong, ask a friend or team member to take a peek at your code and see if any glaring errors (like *syntax error*) pop out.

**Explain your code out loud**

The best way to troubleshoot a sneaky but is to explain out loud each step of your code, and what you hoped to accomplish.

Schedule a meeting with your team to have everyone talk through their code.

If you are alone, try [Rubber Duck Debugging](https://en.wikipedia.org/wiki/Rubber_duck_debugging)!

**Google is your friend**

The whole of the internet is at your disposal! Use it early, use it often.

Some tricks:

-   Copy-paste the exact error message into Google. Chances are, somebody else had a similar problem and got a similar message.

-   Include package names in your search terms. For example, "bar plot in ggplot" is a better search than "bar plot in R".

# Part One: Data import and cleaning

This section will clean today's dataset, so that you can use it more easily in Part Two.

## Data download & packages

First, download the template Quarto file [here()](): 

Next, save the file in your Stat 331 / 531 folder -- this should be in a 
Week 3 or a Practice Activity subfolder! 

Now, open the `PA3_student.qmd` file. At the top of the document, we declare
our package dependencies and load the data.

(Note that the data loading function `read_csv()` will give you an outpouring of helpful information about the dataset. If you do not see the word "error", there is nothing to be concerned about.)

```{r setup}
#| warning: false
#| message: false
#| eval: true

library(tidyverse)

colleges <- read_csv("https://www.dropbox.com/s/bt5hvctdevhbq6j/colleges.csv?dl=1")
```

## Data cleaning

Now we will clean the data. Alas, each of the R chunks in this section will cause an error and / or do the desired task incorrectly. Even the chunks that run without error **are not** correct! You will need to find the mistake and correct it to complete the intended action.

**Step 1:** There are too many variables in this dataset. We don't need all of them. Narrow your dataset down to only:

-   Name of the institution
-   City, State, and ZIP code of the institution
-   The Admissions Rate
-   The average SAT score
-   The number of undergraduate students
-   The in and out of state tuition
-   Whether the school is public or private
-   The "REGION" variable.

```{r select-vars}
colleges_clean <- colleges |> 
  select(INSTNM, CITY, STABBR, ZIP,
         ADM_RATE, SAT_AVG, UGDS,
         TUITIONFEE_IN, TUITIONFEE_OUT,
         CONTROL, REGION) 
```

**Step 2:** Remove the schools that are private and for-profit (category 3).

```{r filter-private-profit}
colleges_clean <- colleges_clean |> 
  filter(CONTROL == 1, CONTROL == 2) 
```

**Step 4:** Adjust the appropriate variables to be numeric.

```{r mutate-numeric}
colleges_clean <- colleges_clean |> 
  mutate(
    TUITIONFEE_IN = numeric(TUITIONFEE_IN),
    TUITIONFEE_OUT = numeric(TUITIONFEE_OUT),
    SAT_AVG = numeric(SAT_AVG),
    ADM_RATE = numeric(ADM_RATE)
    ) 
```

**Step 5:** Adjust the appropriate variables to be factors.

```{r mutate-factor}
colleges_clean |> 
  mutate(
    CONTROL = as.factor(CONTROL),
    REGION = as.factor(REGION)
)
```

**Step 6:** Create a new variable called TUITION_DIFF which contains the difference between in and out of state costs.

```{r mutate-differences}
colleges_clean <- colleges_clean |> 
    TUITION_DIFF = TUITIONFEE_OUT - TUITIONFEE_IN
```

**Step 7:** Remove every row with missing data.

***Note*****:** This is not always a great idea! Usually, even if *some* of the information is missing, we don't want to throw out the entire row. This time, however, we'll be lazy.

```{r drop-na}
colleges_clean <- colleges_clean |> 
  drop.na()
```

Lastly, notice that each of these steps started with

```{r all-together}
#| eval: false

colleges_clean <- colleges_clean |> ...
```

That is pretty redundant! Instead, we could perform all these tasks as one long "pipeline."

**Step 8:** Combine your (fixed) code chunks into a **single** code chunk that carries out all of the steps necessary to clean the data.

**Note:** Think about coding efficiency -- you **should not** have multiple calls to the **same** function!

```{r combine}
# Code combining ALL of your previous steps into ONE pipeline


```

# Part Two: Identify the mystery college

Wow! Your best friend Ephelia has been accepted to her top choice college! Unfortunately, Ephelia is a very mysterious person, and she won't tell you directly which college this is. You'll have to use her clues to figure out which school is her dream school.

Clues:

1.  This college is located in Region 7.

2.  This college's admission rate is above the median rate for the region.

3.  This college **does not** charge the same for in- and out-of-state tuition.

4.  The average SAT score of this college is an odd number.

5.  This college **is not** in Idaho.

6.  Less than 1,000 people apply to this college every year. (Assume the size of the first year class is 1/4 of the undergraduate population.)

7.  The college **is not** in the state where Dr. Theobold received a Ph.D.

8.  Of the three options remaining at this step, Ephelia will attend the cheapest one.
