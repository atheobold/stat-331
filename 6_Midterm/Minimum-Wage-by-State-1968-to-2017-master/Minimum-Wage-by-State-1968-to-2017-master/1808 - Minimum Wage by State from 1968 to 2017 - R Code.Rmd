---
title: "Minimum Wage by State from 1968 to 2017"
author: "Joseph Lisle"
date: "August 2018"
---

# Loading general packages
```{r}
library(tidyverse)
library(dplyr)
```

# Loading in historical minimum wage data by state
```{r, message=FALSE, warning=FALLSE}
# Downloading historical minimum wage data
# Code taken from this website: https://stackoverflow.com/questions/1395528/scraping-html-tables-into-r-data-frames-using-the-xml-package

library(XML)
library(RCurl)
library(rlist)

# Getting URL and loading in table
theurl <- getURL("https://www.dol.gov/whd/state/stateMinWageHis.htm",.opts = list(ssl.verifypeer = FALSE) )
tables <- readHTMLTable(theurl)
tables <- list.clean(tables, fun = is.null, recursive = FALSE)
n.rows <- unlist(lapply(tables, function(t) dim(t)[1]))

# Creating data frames from each table on the page
Table1 <- as.data.frame(tables[1])
Table2 <- as.data.frame(tables[2])
Table3 <- as.data.frame(tables[3])
Table4 <- as.data.frame(tables[4])
Table5 <- as.data.frame(tables[5])
```

# Data Cleaning
## Initial cleaning
```{r}
# All tables need the following quick fixes:
#   1) Unspecified variables names
#   2) random characters ("Â", and "â???" ")
#   3) \r\n for spaces
#   4) 6 spaces where there should be one

# Fixing the variable names
names(Table1) <- c("State", "1968", "1970", "1972", "1976", "1979", "1980", "1981")
names(Table2) <- c("X1", "1988", "1991", "1992", "1994", "1996", "1997", "1998")
names(Table3) <- c("X2", "2000", "2001", "2002", "2003", "2004", "2005", "2006")
names(Table4) <- c("X3", "2007", "2008", "2009", "2010", "2011", "2012", "2013")
names(Table5) <- c("X4", "2014", "2015", "2016", "2017", "", "", "", "", "")

# Removing the extra columns and extra row on the last table
Table5[,6:10] <- NULL
Table5 <- Table5[1:55,]

# Creating one data frame from all of the tables
Data <- cbind(Table1, Table2)
Data <- cbind(Data, Table3)
Data <- cbind(Data, Table4)
Data <- cbind(Data, Table5)

# Removing the unnecessary variables
Data$X1 <- NULL
Data$X2 <- NULL
Data$X3 <- NULL
Data$X4 <- NULL

# Writing a function to fix the issues with the various characters
FixString <- function(x){
  x <- str_remove_all(x, "Â")
  x <- str_remove_all(x, "\r\n ")
  x <- str_replace(x, "â???" ", "-")
  x <- str_replace(x, "      ", " ")
  return(x)
}

# Applying the function to the data frame
Data <- as.list(Data)
Data <- lapply(Data, FixString)
Data <- as.data.frame(Data)
Data
```

## Gathering Data
```{r, warning=FALSE}
# Gathering data frame
Data <- gather(Data, Year, Table_Data, -State)
```

## Cleaning up "Year"
```{r}
# Cleaning "Year" data
Data$Year <- as.numeric(str_remove(Data$Year, "X"))
```

## Adding the footnotes to a new column for easy visualization later one
```{r}
# Moving the footnotes to a new column
# This detects if there are and "[" or "("in the Table_Data column, then moves anything past that character to the Footnote column
Data$Footnote <- as.factor(
  ifelse(str_detect(Data$Table_Data, '\\(') == T,
           substr(Data$Table_Data, regexpr('\\(', Data$Table_Data), str_length(Data$Table_Data)),
  ifelse(str_detect(Data$Table_Data, "\\[") == T,
           substr(Data$Table_Data, regexpr("\\[", Data$Table_Data), str_length(Data$Table_Data)),
         "")))

# ...and cleaning up the "(g,j)" and NA fiasco
Data$Footnote <- as.factor(
  ifelse(Data$Footnote == "(g, j)" |
         Data$Footnote == "(g,,j)" |
         Data$Footnote == "(g,j)",
         "(g, j)",
  ifelse(is.na(Data$Footnote) == T, 
         "",
         as.character(Data$Footnote))))

table(Data$Footnote, useNA = "ifany") # Looks good to go!
```

## Cleaning up the hourly wage data
```{r, warning=FALSE}
# The hourly wage data is really messy! Let's clean this up...
# Here's a function that will do the trick. As there are some ranges and multiple minimum wages for some years and states, I have two functions that will pull the higher or lower of the pair.
High.Wage.Clean <- function(x){
  x <- ifelse(str_detect(x, '\\(') == T, # Removing footnotes - they have their own column now
              substr(x, 0, (regexpr('\\(', x)-1)),
       ifelse(str_detect(x, '\\[') == T,
              substr(x, 0, (regexpr('\\[', x)-1)),
              as.character(x)))
  x <- str_trim(x, side="both") # Removing extra spaces on outsides
  x <- str_replace_all(x, " ", "") # Removing extra spaces within
  x <- str_replace_all(x, "\\$", "") # Removing $s
  x <- str_replace(x, "\\`", "") # Removing `s
  x <- str_replace(x, "\\&", "-") # Making all the ranges uniform for easy handling
  x <- substr(x, (regexpr('-', x)+1), str_length(x)) # Keeping only the higher value
  x <- ifelse(str_detect(x, "wk") == T,  # detecting if it's a weekly/daily minimum and convering to hourly wage at 40 hrs/wk
              substr(x, 0, regexpr('\\/', x)-1) %>%
                as.numeric(.)/40,
       ifelse(str_detect(x, "day") == T,
              substr(x, 0, regexpr('\\/', x)-1) %>%
                as.numeric(.)/8,
       ifelse(x == "...", 0, 
              as.character(x))))
  x <- ifelse(x == "4..65", 4.65, as.numeric(x)) # fixing the double periods
  return(x)
}

Low.Wage.Clean <- function(x){
  x <- ifelse(str_detect(x, '\\(') == T, # Removing footnotes - they have their own column now
              substr(x, 0, (regexpr('\\(', x)-1)),
       ifelse(str_detect(x, '\\[') == T,
              substr(x, 0, (regexpr('\\[', x)-1)),
              as.character(x)))
  x <- str_trim(x, side="both") # Removing extra spaces on outsides
  x <- str_replace_all(x, " ", "") # Removing extra spaces within
  x <- str_replace_all(x, "\\$", "") # Removing $s
  x <- str_replace(x, "\\`", "") # Removing `s
  x <- str_replace(x, "\\&", "-") # Making all the ranges uniform for easy handling
  x <- ifelse(str_detect(x, "-") == T & str_detect(x, "\\/") == T,  # Keeping only the lower value
              paste(substr(x, 1, (regexpr('-', x)-1)),substr(x, (regexpr('\\/', x)),str_length(x))),
       ifelse(str_detect(x, "-") == T,
              substr(x, 1, (regexpr('-', x)-1)),
              as.character(x)))
  x <- ifelse(str_detect(x, "wk") == T,  # detecting if it's a weekly/daily minimum and convering to hourly wage at 40 hrs/wk
              substr(x, 0, regexpr('\\/', x)-1) %>%
                as.numeric(.)/40,
       ifelse(str_detect(x, "day") == T,
              substr(x, 0, regexpr('\\/', x)-1) %>%
                as.numeric(.)/8,
       ifelse(x == "...", 0, 
              as.character(x))))
  x <- ifelse(x == "4..65", 4.65, as.numeric(x)) # fixing the double periods
  return(x)
}

# Now to apply it to the data...
Table_Data <- as.list(Data$Table_Data)

High_Value <- lapply(Table_Data, High.Wage.Clean) # Applying high value and low value extraction functions
Low_Value  <- lapply(Table_Data, Low.Wage.Clean)

High_Value <- as.data.frame(High_Value) # Preparing the new values for import into Data
Low_Value  <- as.data.frame(Low_Value)

High_Value <- gather(High_Value, Random, High.Value) # Further prep. Need to gather the values
Low_Value  <- gather(Low_Value, Random, Low.Value)

# Make sure it's all set...
table(High_Value$High.Value, useNA="ifany")
table(Low_Value$Low.Value, useNA="ifany")

# Add to main dataset
Data$High.Value <- High_Value$High.Value
Data$Low.Value <- Low_Value$Low.Value

# Spot to make sure that the values still make sense
Data %>%
  select(High.Value, Table_Data)

Data %>%
  select(Low.Value, Table_Data)
```

## Adding Missing Values
```{r}
# Because no new legislation took effect in some years, there was no data for those years in the table I scraped earlier in this report
# Although there was no data in the table for these years, it's important that we have the data in the data set as the minimum wage decreased in value during those periods. It will also make the visualizations feel more complete

# There are hardly any missing years, so I'm just going to create an additional dataset for them by hand (it's faster for right now!)
MissingYears <- as.data.frame(c("1969", "1971", "1973", "1974", "1975", "1977", "1978", "1982", "1983", "1984", "1985", "1986", "1987", "1989", "1990", "1993", "1995", "1999"))
MissingYears <- rename(MissingYears, Years = `c("1969", "1971", "1973", "1974", "1975", "1977", "1978", "1982", "1983", "1984", "1985", "1986", "1987", "1989", "1990", "1993", "1995", "1999")`)
MissingYearsList <- c("1969", "1971", "1973", "1974", "1975", "1977", "1978", "1982", "1983", "1984", "1985", "1986", "1987", "1989", "1990", "1993", "1995", "1999")

# Creating a dataset for all the missing values. I only need the first 990 (18 years by 55 "states") rows
States <- Data$State
MissingYears <- merge(MissingYears, States)
MissingYears <- MissingYears[1:990,1:2]
str(MissingYears)

# Adding extra columns for an rbind with Data
MissingYears <- MissingYears %>%
  rename(State = y, Year = Years) %>%
  mutate(Table_Data = "", Footnote = "", High.Value = "", Low.Value = "")

# Binding rows and sorting so that I can add in the missing data in a moment
Data <- rbind(Data, MissingYears)
Data <- Data %>%
  arrange(State, Year)

# Adding in minimum wage, footnotes, and cleaned Value to the missing years dataset
# Here's where I got the base of the formula: https://stackoverflow.com/questions/13155609/returning-above-and-below-rows-of-specific-rows-in-r-dataframe
# Original Minimum Wage Value
for(i in 1:nrow(Data)){
    if(Data$Table_Data[i] != ""){
      Data$Table_Data_Fixed[i] <- Data$Table_Data[i]
    } else if(Data$Table_Data[i] == ""){
      Data$Table_Data_Fixed[i] <- Data$Table_Data_Fixed[(i-1)]
    }
}

# Footnotes
for(i in 1:nrow(Data)){
    if(!(Data$Year[i] %in% MissingYearsList)){
      Data$Footnote_Fixed[i] <- as.character(Data$Footnote[i])
    } else {
      Data$Footnote_Fixed[i] <- as.character(Data$Footnote_Fixed[(i-1)])
    }
}

# Cleaned values
for(i in 1:nrow(Data)){
    if(!(Data$Year[i] %in% MissingYearsList)){
      Data$High.Value_Fixed[i] <- Data$High.Value[i]
    } else {
      Data$High.Value_Fixed[i] <- Data$High.Value_Fixed[(i-1)]
    }
}
for(i in 1:nrow(Data)){
    if(!(Data$Year[i] %in% MissingYearsList)){
      Data$Low.Value_Fixed[i] <- Data$Low.Value[i]
    } else {
      Data$Low.Value_Fixed[i] <- Data$Low.Value_Fixed[(i-1)]
    }
}

# Double checking to make sure everything looks as expected
# Table_Data
Data %>%
  select(Year, Table_Data, Table_Data_Fixed)

# Footnote
Data %>%
  select(Year, Footnote, Footnote_Fixed)

# Value
Data %>%
  select(Year, High.Value, High.Value_Fixed)

Data %>%
  select(Year, Low.Value, Low.Value_Fixed)

# Replacing Old Columns
Data <- Data %>%
  select(State, Year, Table_Data_Fixed, Footnote_Fixed, High.Value_Fixed, Low.Value_Fixed) %>%
  rename(Table_Data = Table_Data_Fixed, Footnote = Footnote_Fixed, High.Value = High.Value_Fixed, Low.Value = Low.Value_Fixed)
```

## Calculating 2018 dollars
```{r}
# It's a fairly simple calculation to calculate 2018 dollars from any point in time!
# Just create an equation (x/y) * b, with the x being the average Consumer Price Index (CPI) from 2018 and y being the average CPI from the other year in the denominator. B is equal to the dollar amount in y's year

# First, I need to add the CPI for each year. Luckily, I can easily get this from the [Bureau of Labor Statistics](https://www.bls.gov/cpi/home.htm)
CPI <- read.csv("CPI 1913 - 2018.csv")

# Now I'll add the CPI Average to my dataset for easy calculation
Data <- merge(x = Data, y = CPI, by = "Year", all.y = F, all.x = T)

# Now calculating 2018 dollars! The CPI for 2018 Jan - Jul is 250.4.
Data$High.2018 <- round((250.4/Data$CPI.Average) * as.numeric(Data$High.Value), 2)
Data$Low.2018 <- round((250.4/Data$CPI.Average) * as.numeric(Data$Low.Value), 2)
```

# Saving Data
```{r}
# The data is ready! Going to make it a bit cleaner to read...
Data <- Data %>%
  arrange(Year, State)

# Writing to CSV
write.csv(Data, file="Minimum Wage Data.csv", row.names = FALSE)
```

```{r}
Data
```